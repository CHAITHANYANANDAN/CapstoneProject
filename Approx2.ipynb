{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "\n",
    "# Optimized Approximate Entropy function with Numba JIT and sliding window\n",
    "@jit(nopython=True)\n",
    "def approximate_entropy(U, m, r):\n",
    "    \"\"\"\n",
    "    Compute Approximate Entropy (ApEn) of a time series in a memory-efficient way.\n",
    "    \n",
    "    Parameters:\n",
    "    U : array-like\n",
    "        The input signal.\n",
    "    m : int\n",
    "        The length of compared run of data.\n",
    "    r : float\n",
    "        The filtering level (standard deviation * r).\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        Approximate entropy of the input signal.\n",
    "    \"\"\"\n",
    "    def _phi(m):\n",
    "        N = len(U)\n",
    "        count = 0\n",
    "        for i in range(N - m):\n",
    "            template = U[i:i + m]\n",
    "            matches = 0\n",
    "            for j in range(N - m):\n",
    "                candidate = U[j:j + m]\n",
    "                if np.max(np.abs(template - candidate)) <= r:\n",
    "                    matches += 1\n",
    "            count += np.log(matches / (N - m + 1))\n",
    "        return count / (N - m + 1)\n",
    "\n",
    "    return abs(_phi(m) - _phi(m + 1))\n",
    "\n",
    "# Sliding window function for Approximate Entropy\n",
    "def calculate_apen_sliding_window(signal, m=2, r_factor=0.2, window_size=128, step_size=64):\n",
    "    \"\"\"\n",
    "    Compute Approximate Entropy using a sliding window approach.\n",
    "    \n",
    "    Parameters:\n",
    "    signal : array-like\n",
    "        The input signal (EEG data).\n",
    "    m : int\n",
    "        The embedding dimension.\n",
    "    r_factor : float\n",
    "        The factor to calculate the tolerance level (r = r_factor * std).\n",
    "    window_size : int\n",
    "        Size of the sliding window (number of samples).\n",
    "    step_size : int\n",
    "        Step size for the sliding window (how many samples to shift).\n",
    "    \n",
    "    Returns:\n",
    "    array\n",
    "        Approximate entropy for each window.\n",
    "    \"\"\"\n",
    "    r = r_factor * np.std(signal)  # Set r based on the standard deviation of the signal\n",
    "    apen_values = []\n",
    "\n",
    "    # Slide the window across the signal\n",
    "    for start in range(0, len(signal) - window_size + 1, step_size):\n",
    "        window = signal[start:start + window_size]\n",
    "        apen_value = approximate_entropy(window, m=m, r=r)\n",
    "        apen_values.append(apen_value)\n",
    "\n",
    "    return np.array(apen_values)\n",
    "\n",
    "# Function to read and process large EEG data in chunks if needed\n",
    "def calculate_apen_for_large_data(preprocessed_file, eeg_channel, m=2, r_factor=0.2, window_size=128, step_size=64, chunksize=100000):\n",
    "    \"\"\"\n",
    "    Compute Approximate Entropy for large EEG data using sliding windows and chunk processing.\n",
    "    \n",
    "    Parameters:\n",
    "    preprocessed_file : str\n",
    "        Path to the preprocessed EEG CSV file.\n",
    "    eeg_channel : str\n",
    "        Name of the EEG channel column in the CSV file.\n",
    "    m : int\n",
    "        Embedding dimension for ApEn calculation.\n",
    "    r_factor : float\n",
    "        Tolerance factor.\n",
    "    window_size : int\n",
    "        Size of sliding window.\n",
    "    step_size : int\n",
    "        Step size for sliding window.\n",
    "    chunksize : int\n",
    "        Number of samples to read at a time from the file.\n",
    "    \n",
    "    Returns:\n",
    "    array\n",
    "        Approximate entropy for each window in the large dataset.\n",
    "    \"\"\"\n",
    "    apen_values = []\n",
    "\n",
    "    # Load data in chunks to avoid memory overload\n",
    "    for chunk in pd.read_csv(preprocessed_file, chunksize=chunksize):\n",
    "        signal = chunk[eeg_channel].values\n",
    "        apen_chunk_values = calculate_apen_sliding_window(signal, m, r_factor, window_size, step_size)\n",
    "        apen_values.extend(apen_chunk_values)\n",
    "\n",
    "    return np.array(apen_values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate Entropy values: [0.6438188  0.60599725 0.71156773 ... 0.38065699 0.32595    0.50583927]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    apen_values = calculate_apen_for_large_data('preprocessed_eeg_data.csv', 'Fz', window_size=128, step_size=64)\n",
    "    print(\"Approximate Entropy values:\", apen_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import os\n",
    "\n",
    "# Optimized Approximate Entropy function with Numba JIT\n",
    "@jit(nopython=True)\n",
    "def approximate_entropy(U, m, r):\n",
    "    \"\"\"\n",
    "    Compute Approximate Entropy (ApEn) of a time series.\n",
    "    \n",
    "    Parameters:\n",
    "    U : array-like\n",
    "        The input signal.\n",
    "    m : int\n",
    "        The length of compared run of data.\n",
    "    r : float\n",
    "        The filtering level (standard deviation * r).\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        Approximate entropy of the input signal.\n",
    "    \"\"\"\n",
    "    def _phi(m):\n",
    "        N = len(U)\n",
    "        count = 0\n",
    "        for i in range(N - m):\n",
    "            template = U[i:i + m]\n",
    "            matches = 0\n",
    "            for j in range(N - m):\n",
    "                candidate = U[j:j + m]\n",
    "                if np.max(np.abs(template - candidate)) <= r:\n",
    "                    matches += 1\n",
    "            count += np.log(matches / (N - m + 1))\n",
    "        return count / (N - m + 1)\n",
    "\n",
    "    return abs(_phi(m) - _phi(m + 1))\n",
    "\n",
    "# Function to calculate ApEn for each feature of a single patient\n",
    "def calculate_apen_for_patient(eeg_data, patient_id, m=2, r_factor=0.2):\n",
    "    \"\"\"\n",
    "    Calculate Approximate Entropy for all features of a single patient.\n",
    "    \n",
    "    Parameters:\n",
    "    eeg_data : DataFrame\n",
    "        EEG data of a single patient with 19 features (channels).\n",
    "    patient_id : str\n",
    "        Identifier for the patient (Patient_ID).\n",
    "    m : int\n",
    "        The embedding dimension for ApEn calculation.\n",
    "    r_factor : float\n",
    "        Tolerance factor for ApEn calculation.\n",
    "        \n",
    "    Returns:\n",
    "    DataFrame\n",
    "        A DataFrame with Patient_ID and ApEn values for each channel.\n",
    "    \"\"\"\n",
    "    apen_results = {'Patient_ID': patient_id}\n",
    "    \n",
    "    for channel in eeg_data.columns:\n",
    "        signal = eeg_data[channel].values\n",
    "        r = r_factor * np.std(signal)  # Set tolerance based on signal's standard deviation\n",
    "        apen_value = approximate_entropy(signal, m=m, r=r)\n",
    "        apen_results[channel] = apen_value\n",
    "    \n",
    "    # Convert the results to a DataFrame\n",
    "    apen_df = pd.DataFrame([apen_results])\n",
    "    \n",
    "    return apen_df\n",
    "\n",
    "# Function to calculate ApEn for each patient in a preprocessed file\n",
    "def process_patients_in_file(preprocessed_file,output_directory, m=2, r_factor=0.2):\n",
    "    \"\"\"\n",
    "    Calculate Approximate Entropy for all patients in the preprocessed file.\n",
    "    \n",
    "    Parameters:\n",
    "    preprocessed_file : str\n",
    "        Path to the preprocessed EEG CSV file containing multiple patients.\n",
    "    m : int\n",
    "        Embedding dimension for ApEn calculation.\n",
    "    r_factor : float\n",
    "        Tolerance factor for ApEn calculation.\n",
    "        \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Load preprocessed EEG data\n",
    "    df = pd.read_csv(preprocessed_file)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    # Group by Patient_ID and process each patient's data separately\n",
    "    patient_groups = df.groupby('Patient_ID')\n",
    "    \n",
    "    # Loop through each patient group and calculate ApEn for all 19 features\n",
    "    for patient_id, patient_data in patient_groups:\n",
    "        # Drop metadata columns (Label, Patient_ID) to focus only on EEG features\n",
    "        eeg_data = patient_data.drop(columns=['Label', 'Patient_ID'])\n",
    "        \n",
    "        # Calculate ApEn for the patient\n",
    "        apen_df = calculate_apen_for_patient(eeg_data, patient_id, m=m, r_factor=r_factor)\n",
    "        \n",
    "        # Save the result to a CSV file named after the patient\n",
    "        output_file = os.path.join(output_directory, f'approx_entropy_patient_{patient_id}.csv')\n",
    "        apen_df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved Approximate Entropy results for patient {patient_id} to {output_file}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Approximate Entropy results for patient v107_v107.csv to ApproximatedData\\approx_entropy_patient_v107_v107.csv.csv\n",
      "Saved Approximate Entropy results for patient v108_v108.csv to ApproximatedData\\approx_entropy_patient_v108_v108.csv.csv\n",
      "Saved Approximate Entropy results for patient v109_v109.csv to ApproximatedData\\approx_entropy_patient_v109_v109.csv.csv\n",
      "Saved Approximate Entropy results for patient v10p_v10p.csv to ApproximatedData\\approx_entropy_patient_v10p_v10p.csv.csv\n",
      "Saved Approximate Entropy results for patient v110_v110.csv to ApproximatedData\\approx_entropy_patient_v110_v110.csv.csv\n",
      "Saved Approximate Entropy results for patient v111_v111.csv to ApproximatedData\\approx_entropy_patient_v111_v111.csv.csv\n",
      "Saved Approximate Entropy results for patient v112_v112.csv to ApproximatedData\\approx_entropy_patient_v112_v112.csv.csv\n",
      "Saved Approximate Entropy results for patient v113_v113.csv to ApproximatedData\\approx_entropy_patient_v113_v113.csv.csv\n",
      "Saved Approximate Entropy results for patient v114_v114.csv to ApproximatedData\\approx_entropy_patient_v114_v114.csv.csv\n",
      "Saved Approximate Entropy results for patient v115_v115.csv to ApproximatedData\\approx_entropy_patient_v115_v115.csv.csv\n",
      "Saved Approximate Entropy results for patient v116_v116.csv to ApproximatedData\\approx_entropy_patient_v116_v116.csv.csv\n",
      "Saved Approximate Entropy results for patient v117_v117.csv to ApproximatedData\\approx_entropy_patient_v117_v117.csv.csv\n",
      "Saved Approximate Entropy results for patient v118_v118.csv to ApproximatedData\\approx_entropy_patient_v118_v118.csv.csv\n",
      "Saved Approximate Entropy results for patient v120_v120.csv to ApproximatedData\\approx_entropy_patient_v120_v120.csv.csv\n",
      "Saved Approximate Entropy results for patient v121_v121.csv to ApproximatedData\\approx_entropy_patient_v121_v121.csv.csv\n",
      "Saved Approximate Entropy results for patient v123_v123.csv to ApproximatedData\\approx_entropy_patient_v123_v123.csv.csv\n",
      "Saved Approximate Entropy results for patient v125_v125.csv to ApproximatedData\\approx_entropy_patient_v125_v125.csv.csv\n",
      "Saved Approximate Entropy results for patient v127_v127.csv to ApproximatedData\\approx_entropy_patient_v127_v127.csv.csv\n",
      "Saved Approximate Entropy results for patient v129_v129.csv to ApproximatedData\\approx_entropy_patient_v129_v129.csv.csv\n",
      "Saved Approximate Entropy results for patient v12p_v12p.csv to ApproximatedData\\approx_entropy_patient_v12p_v12p.csv.csv\n",
      "Saved Approximate Entropy results for patient v131_v131.csv to ApproximatedData\\approx_entropy_patient_v131_v131.csv.csv\n",
      "Saved Approximate Entropy results for patient v133_v133.csv to ApproximatedData\\approx_entropy_patient_v133_v133.csv.csv\n",
      "Saved Approximate Entropy results for patient v134_v134.csv to ApproximatedData\\approx_entropy_patient_v134_v134.csv.csv\n",
      "Saved Approximate Entropy results for patient v138_v138.csv to ApproximatedData\\approx_entropy_patient_v138_v138.csv.csv\n",
      "Saved Approximate Entropy results for patient v140_v140.csv to ApproximatedData\\approx_entropy_patient_v140_v140.csv.csv\n",
      "Saved Approximate Entropy results for patient v143_v143.csv to ApproximatedData\\approx_entropy_patient_v143_v143.csv.csv\n",
      "Saved Approximate Entropy results for patient v147_v147.csv to ApproximatedData\\approx_entropy_patient_v147_v147.csv.csv\n",
      "Saved Approximate Entropy results for patient v149_v149.csv to ApproximatedData\\approx_entropy_patient_v149_v149.csv.csv\n",
      "Saved Approximate Entropy results for patient v14p_v14p.csv to ApproximatedData\\approx_entropy_patient_v14p_v14p.csv.csv\n",
      "Saved Approximate Entropy results for patient v151_v151.csv to ApproximatedData\\approx_entropy_patient_v151_v151.csv.csv\n",
      "Saved Approximate Entropy results for patient v15p_v15p.csv to ApproximatedData\\approx_entropy_patient_v15p_v15p.csv.csv\n",
      "Saved Approximate Entropy results for patient v173_v173.csv to ApproximatedData\\approx_entropy_patient_v173_v173.csv.csv\n",
      "Saved Approximate Entropy results for patient v177_v177.csv to ApproximatedData\\approx_entropy_patient_v177_v177.csv.csv\n",
      "Saved Approximate Entropy results for patient v179_v179.csv to ApproximatedData\\approx_entropy_patient_v179_v179.csv.csv\n",
      "Saved Approximate Entropy results for patient v181_v181.csv to ApproximatedData\\approx_entropy_patient_v181_v181.csv.csv\n",
      "Saved Approximate Entropy results for patient v183_v183.csv to ApproximatedData\\approx_entropy_patient_v183_v183.csv.csv\n",
      "Saved Approximate Entropy results for patient v18p_v18p.csv to ApproximatedData\\approx_entropy_patient_v18p_v18p.csv.csv\n",
      "Saved Approximate Entropy results for patient v190_v190.csv to ApproximatedData\\approx_entropy_patient_v190_v190.csv.csv\n",
      "Saved Approximate Entropy results for patient v196_v196.csv to ApproximatedData\\approx_entropy_patient_v196_v196.csv.csv\n",
      "Saved Approximate Entropy results for patient v198_v198.csv to ApproximatedData\\approx_entropy_patient_v198_v198.csv.csv\n",
      "Saved Approximate Entropy results for patient v19p_v19p.csv to ApproximatedData\\approx_entropy_patient_v19p_v19p.csv.csv\n",
      "Saved Approximate Entropy results for patient v1p_v1p.csv to ApproximatedData\\approx_entropy_patient_v1p_v1p.csv.csv\n",
      "Saved Approximate Entropy results for patient v200_v200.csv to ApproximatedData\\approx_entropy_patient_v200_v200.csv.csv\n",
      "Saved Approximate Entropy results for patient v204_v204.csv to ApproximatedData\\approx_entropy_patient_v204_v204.csv.csv\n",
      "Saved Approximate Entropy results for patient v206_v206.csv to ApproximatedData\\approx_entropy_patient_v206_v206.csv.csv\n",
      "Saved Approximate Entropy results for patient v209_v209.csv to ApproximatedData\\approx_entropy_patient_v209_v209.csv.csv\n",
      "Saved Approximate Entropy results for patient v20p_v20p.csv to ApproximatedData\\approx_entropy_patient_v20p_v20p.csv.csv\n",
      "Saved Approximate Entropy results for patient v213_v213.csv to ApproximatedData\\approx_entropy_patient_v213_v213.csv.csv\n",
      "Saved Approximate Entropy results for patient v215_v215.csv to ApproximatedData\\approx_entropy_patient_v215_v215.csv.csv\n",
      "Saved Approximate Entropy results for patient v219_v219.csv to ApproximatedData\\approx_entropy_patient_v219_v219.csv.csv\n",
      "Saved Approximate Entropy results for patient v21p_v21p.csv to ApproximatedData\\approx_entropy_patient_v21p_v21p.csv.csv\n",
      "Saved Approximate Entropy results for patient v227_v227.csv to ApproximatedData\\approx_entropy_patient_v227_v227.csv.csv\n",
      "Saved Approximate Entropy results for patient v22p_v22p.csv to ApproximatedData\\approx_entropy_patient_v22p_v22p.csv.csv\n",
      "Saved Approximate Entropy results for patient v231_v231.csv to ApproximatedData\\approx_entropy_patient_v231_v231.csv.csv\n",
      "Saved Approximate Entropy results for patient v234_v234.csv to ApproximatedData\\approx_entropy_patient_v234_v234.csv.csv\n",
      "Saved Approximate Entropy results for patient v236_v236.csv to ApproximatedData\\approx_entropy_patient_v236_v236.csv.csv\n",
      "Saved Approximate Entropy results for patient v238_v238.csv to ApproximatedData\\approx_entropy_patient_v238_v238.csv.csv\n",
      "Saved Approximate Entropy results for patient v244_v244.csv to ApproximatedData\\approx_entropy_patient_v244_v244.csv.csv\n",
      "Saved Approximate Entropy results for patient v246_v246.csv to ApproximatedData\\approx_entropy_patient_v246_v246.csv.csv\n",
      "Saved Approximate Entropy results for patient v24p_v24p.csv to ApproximatedData\\approx_entropy_patient_v24p_v24p.csv.csv\n",
      "Saved Approximate Entropy results for patient v250_v250.csv to ApproximatedData\\approx_entropy_patient_v250_v250.csv.csv\n",
      "Saved Approximate Entropy results for patient v254_v254.csv to ApproximatedData\\approx_entropy_patient_v254_v254.csv.csv\n",
      "Saved Approximate Entropy results for patient v25p_v25p.csv to ApproximatedData\\approx_entropy_patient_v25p_v25p.csv.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the preprocessed EEG file (containing multiple patients)\n",
    "    preprocessed_file = 'preprocessed_eeg_data.csv'\n",
    "    output_directory = 'ApproximatedData'\n",
    "    # Process all patients in the file\n",
    "    process_patients_in_file(preprocessed_file,output_directory, m=2, r_factor=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "\n",
    "# Optimized Approximate Entropy function with Numba JIT\n",
    "@jit(nopython=True)\n",
    "def approximate_entropy(U, m, r):\n",
    "    \"\"\"\n",
    "    Compute Approximate Entropy (ApEn) of a time series.\n",
    "    \n",
    "    Parameters:\n",
    "    U : array-like\n",
    "        The input signal.\n",
    "    m : int\n",
    "        The length of compared run of data.\n",
    "    r : float\n",
    "        The filtering level (standard deviation * r).\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        Approximate entropy of the input signal.\n",
    "    \"\"\"\n",
    "    def _phi(m):\n",
    "        N = len(U)\n",
    "        count = 0\n",
    "        for i in range(N - m):\n",
    "            template = U[i:i + m]\n",
    "            matches = 0\n",
    "            for j in range(N - m):\n",
    "                candidate = U[j:j + m]\n",
    "                if np.max(np.abs(template - candidate)) <= r:\n",
    "                    matches += 1\n",
    "            count += np.log(matches / (N - m + 1))\n",
    "        return count / (N - m + 1)\n",
    "\n",
    "    return abs(_phi(m) - _phi(m + 1))\n",
    "\n",
    "# Function to calculate ApEn for each feature of a single patient\n",
    "def calculate_apen_for_patient(eeg_data, patient_id, m=2, r_factor=0.2):\n",
    "    \"\"\"\n",
    "    Calculate Approximate Entropy for all features of a single patient.\n",
    "    \n",
    "    Parameters:\n",
    "    eeg_data : DataFrame\n",
    "        EEG data of a single patient with 19 features (channels).\n",
    "    patient_id : str\n",
    "        Identifier for the patient (Patient_ID).\n",
    "    m : int\n",
    "        The embedding dimension for ApEn calculation.\n",
    "    r_factor : float\n",
    "        Tolerance factor for ApEn calculation.\n",
    "        \n",
    "    Returns:\n",
    "    DataFrame\n",
    "        A DataFrame with Patient_ID and ApEn values for each channel.\n",
    "    \"\"\"\n",
    "    apen_results = {'Patient_ID': patient_id}\n",
    "    \n",
    "    for channel in eeg_data.columns:\n",
    "        signal = eeg_data[channel].values\n",
    "        r = r_factor * np.std(signal)  # Set tolerance based on signal's standard deviation\n",
    "        apen_value = approximate_entropy(signal, m=m, r=r)\n",
    "        apen_results[channel] = apen_value\n",
    "    \n",
    "    # Convert the results to a DataFrame\n",
    "    apen_df = pd.DataFrame([apen_results])\n",
    "    \n",
    "    return apen_df\n",
    "\n",
    "# Function to calculate ApEn for each patient and skip already processed patients\n",
    "def process_patients_in_file(preprocessed_file, output_directory, m=2, r_factor=0.2):\n",
    "    \"\"\"\n",
    "    Calculate Approximate Entropy for all patients in the preprocessed file,\n",
    "    skipping patients that have already been processed.\n",
    "    \n",
    "    Parameters:\n",
    "    preprocessed_file : str\n",
    "        Path to the preprocessed EEG CSV file containing multiple patients.\n",
    "    m : int\n",
    "        Embedding dimension for ApEn calculation.\n",
    "    r_factor : float\n",
    "        Tolerance factor for ApEn calculation.\n",
    "        \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Load preprocessed EEG data\n",
    "    df = pd.read_csv(preprocessed_file)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Group by Patient_ID and process each patient's data\n",
    "    patient_groups = df.groupby('Patient_ID')\n",
    "\n",
    "    # Get list of already processed patient files in the output directory\n",
    "    processed_patients = {\n",
    "        filename.replace('approx_entropy_patient_', '').replace('.csv', '')\n",
    "        for filename in os.listdir(output_directory)\n",
    "        if filename.startswith('approx_entropy_patient_')\n",
    "    }\n",
    "\n",
    "    # Process only patients that haven't been processed yet\n",
    "    for patient_id, patient_data in patient_groups:\n",
    "        # Convert patient_id to string and clean it\n",
    "        patient_id_str = str(patient_id).replace('.csv', '')\n",
    "\n",
    "        # Skip if this patient's file is already processed\n",
    "        if patient_id_str in processed_patients:\n",
    "            print(f\"Skipping patient {patient_id_str} (already processed)\")\n",
    "            continue\n",
    "\n",
    "        # Drop metadata columns (Label, Patient_ID) to focus only on EEG features\n",
    "        eeg_data = patient_data.drop(columns=['Label', 'Patient_ID'])\n",
    "        \n",
    "        # Calculate ApEn for the patient\n",
    "        apen_df = calculate_apen_for_patient(eeg_data, patient_id_str, m=m, r_factor=r_factor)\n",
    "        \n",
    "        # Save the result to a CSV file named after the patient\n",
    "        output_file = os.path.join(output_directory, f'approx_entropy_patient_{patient_id_str}.csv')\n",
    "        apen_df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved Approximate Entropy results for patient {patient_id_str} to {output_file}\")\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping patient v107_v107 (already processed)\n",
      "Skipping patient v108_v108 (already processed)\n",
      "Skipping patient v109_v109 (already processed)\n",
      "Skipping patient v10p_v10p (already processed)\n",
      "Skipping patient v110_v110 (already processed)\n",
      "Skipping patient v111_v111 (already processed)\n",
      "Skipping patient v112_v112 (already processed)\n",
      "Skipping patient v113_v113 (already processed)\n",
      "Skipping patient v114_v114 (already processed)\n",
      "Skipping patient v115_v115 (already processed)\n",
      "Skipping patient v116_v116 (already processed)\n",
      "Skipping patient v117_v117 (already processed)\n",
      "Skipping patient v118_v118 (already processed)\n",
      "Skipping patient v120_v120 (already processed)\n",
      "Skipping patient v121_v121 (already processed)\n",
      "Skipping patient v123_v123 (already processed)\n",
      "Skipping patient v125_v125 (already processed)\n",
      "Skipping patient v127_v127 (already processed)\n",
      "Skipping patient v129_v129 (already processed)\n",
      "Skipping patient v12p_v12p (already processed)\n",
      "Skipping patient v131_v131 (already processed)\n",
      "Skipping patient v133_v133 (already processed)\n",
      "Skipping patient v134_v134 (already processed)\n",
      "Skipping patient v138_v138 (already processed)\n",
      "Skipping patient v140_v140 (already processed)\n",
      "Skipping patient v143_v143 (already processed)\n",
      "Skipping patient v147_v147 (already processed)\n",
      "Skipping patient v149_v149 (already processed)\n",
      "Skipping patient v14p_v14p (already processed)\n",
      "Skipping patient v151_v151 (already processed)\n",
      "Skipping patient v15p_v15p (already processed)\n",
      "Skipping patient v173_v173 (already processed)\n",
      "Skipping patient v177_v177 (already processed)\n",
      "Skipping patient v179_v179 (already processed)\n",
      "Skipping patient v181_v181 (already processed)\n",
      "Skipping patient v183_v183 (already processed)\n",
      "Skipping patient v18p_v18p (already processed)\n",
      "Skipping patient v190_v190 (already processed)\n",
      "Skipping patient v196_v196 (already processed)\n",
      "Skipping patient v198_v198 (already processed)\n",
      "Skipping patient v19p_v19p (already processed)\n",
      "Skipping patient v1p_v1p (already processed)\n",
      "Skipping patient v200_v200 (already processed)\n",
      "Skipping patient v204_v204 (already processed)\n",
      "Skipping patient v206_v206 (already processed)\n",
      "Skipping patient v209_v209 (already processed)\n",
      "Skipping patient v20p_v20p (already processed)\n",
      "Skipping patient v213_v213 (already processed)\n",
      "Skipping patient v215_v215 (already processed)\n",
      "Skipping patient v219_v219 (already processed)\n",
      "Skipping patient v21p_v21p (already processed)\n",
      "Skipping patient v227_v227 (already processed)\n",
      "Skipping patient v22p_v22p (already processed)\n",
      "Skipping patient v231_v231 (already processed)\n",
      "Skipping patient v234_v234 (already processed)\n",
      "Skipping patient v236_v236 (already processed)\n",
      "Skipping patient v238_v238 (already processed)\n",
      "Skipping patient v244_v244 (already processed)\n",
      "Skipping patient v246_v246 (already processed)\n",
      "Skipping patient v24p_v24p (already processed)\n",
      "Skipping patient v250_v250 (already processed)\n",
      "Skipping patient v254_v254 (already processed)\n",
      "Skipping patient v25p_v25p (already processed)\n",
      "Skipping patient v263_v263 (already processed)\n",
      "Skipping patient v265_v265 (already processed)\n",
      "Skipping patient v270_v270 (already processed)\n",
      "Skipping patient v274_v274 (already processed)\n",
      "Skipping patient v279_v279 (already processed)\n",
      "Skipping patient v27p_v27p (already processed)\n",
      "Skipping patient v284_v284 (already processed)\n",
      "Skipping patient v286_v286 (already processed)\n",
      "Skipping patient v288_v288 (already processed)\n",
      "Skipping patient v28p_v28p (already processed)\n",
      "Skipping patient v297_v297 (already processed)\n",
      "Skipping patient v298_v298 (already processed)\n",
      "Skipping patient v299_v299 (already processed)\n",
      "Skipping patient v29p_v29p (already processed)\n",
      "Skipping patient v300_v300 (already processed)\n",
      "Skipping patient v302_v302 (already processed)\n",
      "Skipping patient v303_v303 (already processed)\n",
      "Skipping patient v304_v304 (already processed)\n",
      "Skipping patient v305_v305 (already processed)\n",
      "Skipping patient v306_v306 (already processed)\n",
      "Skipping patient v307_v307 (already processed)\n",
      "Skipping patient v308_v308 (already processed)\n",
      "Skipping patient v309_v309 (already processed)\n",
      "Skipping patient v30p_v30p (already processed)\n",
      "Skipping patient v310_v310 (already processed)\n",
      "Skipping patient v31p_v31p (already processed)\n",
      "Skipping patient v32p_v32p (already processed)\n",
      "Skipping patient v33p_v33p (already processed)\n",
      "Skipping patient v34p_v34p (already processed)\n",
      "Skipping patient v35p_v35p (already processed)\n",
      "Skipping patient v36p_v36p (already processed)\n",
      "Skipping patient v37p_v37p (already processed)\n",
      "Skipping patient v38p_v38p (already processed)\n",
      "Skipping patient v39p_v39p (already processed)\n",
      "Skipping patient v3p_v3p (already processed)\n",
      "Skipping patient v40p_v40p (already processed)\n",
      "Skipping patient v41p_v41p (already processed)\n",
      "Skipping patient v42p_v42p (already processed)\n",
      "Skipping patient v43p_v43p (already processed)\n",
      "Skipping patient v44p_v44p (already processed)\n",
      "Skipping patient v45p_v45p (already processed)\n",
      "Skipping patient v46p_v46p (already processed)\n",
      "Skipping patient v47p_v47p (already processed)\n",
      "Skipping patient v48p_v48p (already processed)\n",
      "Skipping patient v49p_v49p (already processed)\n",
      "Skipping patient v50p_v50p (already processed)\n",
      "Skipping patient v51p_v51p (already processed)\n",
      "Skipping patient v52p_v52p (already processed)\n",
      "Skipping patient v53p_v53p (already processed)\n",
      "Skipping patient v54p_v54p (already processed)\n",
      "Skipping patient v55p_v55p (already processed)\n",
      "Skipping patient v56p_v56p (already processed)\n",
      "Skipping patient v57p_v57p (already processed)\n",
      "Skipping patient v58p_v58p (already processed)\n",
      "Skipping patient v59p_v59p (already processed)\n",
      "Saved Approximate Entropy results for patient v60p_v60p to ApproximatedData\\approx_entropy_patient_v60p_v60p.csv\n",
      "Saved Approximate Entropy results for patient v6p_v6p to ApproximatedData\\approx_entropy_patient_v6p_v6p.csv\n",
      "Saved Approximate Entropy results for patient v8p_v8p to ApproximatedData\\approx_entropy_patient_v8p_v8p.csv\n"
     ]
    }
   ],
   "source": [
    "#  Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the preprocessed EEG file (containing multiple patients)\n",
    "    preprocessed_file = 'preprocessed_eeg_data.csv'\n",
    "    output_directory = 'ApproximatedData'\n",
    "    \n",
    "    # Process all patients in the file, skipping already processed patients\n",
    "    process_patients_in_file(preprocessed_file, output_directory, m=2, r_factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Function to load class labels from the preprocessed EEG data\n",
    "def load_class_labels(preprocessed_file):\n",
    "   \n",
    "    # Load the preprocessed EEG data\n",
    "    df = pd.read_csv(preprocessed_file)\n",
    "    \n",
    "    # Create a dictionary with Patient_ID as keys and class labels as values\n",
    "    class_labels = df[['Patient_ID', 'Label']].drop_duplicates()\n",
    "    class_label_dict = dict(zip(class_labels['Patient_ID'], class_labels['Label']))\n",
    "    \n",
    "    return class_label_dict\n",
    "\n",
    "# Function to combine Approximate Entropy values with class labels\n",
    "def combine_entropy_with_class(approx_entropy_folder, class_label_dict, output_file):\n",
    "    \n",
    "    combined_data = []  # List to store combined data for all patients\n",
    "    \n",
    "    # Loop through each Approximate Entropy CSV file\n",
    "    for file_name in os.listdir(approx_entropy_folder):\n",
    "        if file_name.endswith('.csv'):  # Ensure we're processing CSV files\n",
    "            file_path = os.path.join(approx_entropy_folder, file_name)\n",
    "            # Load the Approximate Entropy data\n",
    "            df = pd.read_csv(file_path)\n",
    "            patient_id = df['Patient_ID'].iloc[0]\n",
    "            \n",
    "            # Get the class label for the patient\n",
    "            class_label = class_label_dict.get(patient_id, 'Unknown')\n",
    "            \n",
    "            # Add the class label to the Approximate Entropy DataFrame\n",
    "            df['Class_Label'] = class_label\n",
    "            \n",
    "            # Append the DataFrame to the combined data list\n",
    "            combined_data.append(df)\n",
    "    \n",
    "    # Concatenate all data into a single DataFrame\n",
    "    combined_df = pd.concat(combined_data, ignore_index=True)\n",
    "    \n",
    "    # Save the combined data to a new CSV file\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined data saved to {output_file}\")\n",
    "\n",
    "# Main function to process everything\n",
    "def process_approx_entropy_with_labels(preprocessed_file, approx_entropy_folder, output_file):\n",
    "  \n",
    "    # Load class labels from the preprocessed EEG data\n",
    "    class_label_dict = load_class_labels(preprocessed_file)\n",
    "    \n",
    "    # Combine Approximate Entropy values with class labels\n",
    "    combine_entropy_with_class(approx_entropy_folder, class_label_dict, output_file)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved to combined_entropy_with_class.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "   \n",
    "    preprocessed_file = 'preprocessed_eeg_data.csv'\n",
    "    approx_entropy_folder = 'ApproximatedData'\n",
    "    output_file = 'combined_entropy_with_class.csv'\n",
    "\n",
    "    process_approx_entropy_with_labels(preprocessed_file, approx_entropy_folder, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
