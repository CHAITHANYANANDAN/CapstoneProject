{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "\n",
    "# Optimized Approximate Entropy function with Numba JIT and sliding window\n",
    "@jit(nopython=True)\n",
    "def approximate_entropy(U, m, r):\n",
    "    \"\"\"\n",
    "    Compute Approximate Entropy (ApEn) of a time series in a memory-efficient way.\n",
    "    \n",
    "    Parameters:\n",
    "    U : array-like\n",
    "        The input signal.\n",
    "    m : int\n",
    "        The length of compared run of data.\n",
    "    r : float\n",
    "        The filtering level (standard deviation * r).\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        Approximate entropy of the input signal.\n",
    "    \"\"\"\n",
    "    def _phi(m):\n",
    "        N = len(U)\n",
    "        count = 0\n",
    "        for i in range(N - m):\n",
    "            template = U[i:i + m]\n",
    "            matches = 0\n",
    "            for j in range(N - m):\n",
    "                candidate = U[j:j + m]\n",
    "                if np.max(np.abs(template - candidate)) <= r:\n",
    "                    matches += 1\n",
    "            count += np.log(matches / (N - m + 1))\n",
    "        return count / (N - m + 1)\n",
    "\n",
    "    return abs(_phi(m) - _phi(m + 1))\n",
    "\n",
    "# Sliding window function for Approximate Entropy\n",
    "def calculate_apen_sliding_window(signal, m=2, r_factor=0.2, window_size=128, step_size=64):\n",
    "    \"\"\"\n",
    "    Compute Approximate Entropy using a sliding window approach.\n",
    "    \n",
    "    Parameters:\n",
    "    signal : array-like\n",
    "        The input signal (EEG data).\n",
    "    m : int\n",
    "        The embedding dimension.\n",
    "    r_factor : float\n",
    "        The factor to calculate the tolerance level (r = r_factor * std).\n",
    "    window_size : int\n",
    "        Size of the sliding window (number of samples).\n",
    "    step_size : int\n",
    "        Step size for the sliding window (how many samples to shift).\n",
    "    \n",
    "    Returns:\n",
    "    array\n",
    "        Approximate entropy for each window.\n",
    "    \"\"\"\n",
    "    r = r_factor * np.std(signal)  # Set r based on the standard deviation of the signal\n",
    "    apen_values = []\n",
    "\n",
    "    # Slide the window across the signal\n",
    "    for start in range(0, len(signal) - window_size + 1, step_size):\n",
    "        window = signal[start:start + window_size]\n",
    "        apen_value = approximate_entropy(window, m=m, r=r)\n",
    "        apen_values.append(apen_value)\n",
    "\n",
    "    return np.array(apen_values)\n",
    "\n",
    "# Function to read and process large EEG data in chunks if needed\n",
    "def calculate_apen_for_large_data(preprocessed_file, eeg_channel, m=2, r_factor=0.2, window_size=128, step_size=64, chunksize=100000):\n",
    "    \"\"\"\n",
    "    Compute Approximate Entropy for large EEG data using sliding windows and chunk processing.\n",
    "    \n",
    "    Parameters:\n",
    "    preprocessed_file : str\n",
    "        Path to the preprocessed EEG CSV file.\n",
    "    eeg_channel : str\n",
    "        Name of the EEG channel column in the CSV file.\n",
    "    m : int\n",
    "        Embedding dimension for ApEn calculation.\n",
    "    r_factor : float\n",
    "        Tolerance factor.\n",
    "    window_size : int\n",
    "        Size of sliding window.\n",
    "    step_size : int\n",
    "        Step size for sliding window.\n",
    "    chunksize : int\n",
    "        Number of samples to read at a time from the file.\n",
    "    \n",
    "    Returns:\n",
    "    array\n",
    "        Approximate entropy for each window in the large dataset.\n",
    "    \"\"\"\n",
    "    apen_values = []\n",
    "\n",
    "    # Load data in chunks to avoid memory overload\n",
    "    for chunk in pd.read_csv(preprocessed_file, chunksize=chunksize):\n",
    "        signal = chunk[eeg_channel].values\n",
    "        apen_chunk_values = calculate_apen_sliding_window(signal, m, r_factor, window_size, step_size)\n",
    "        apen_values.extend(apen_chunk_values)\n",
    "\n",
    "    return np.array(apen_values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate Entropy values: [0.6438188  0.60599725 0.71156773 ... 0.38065699 0.32595    0.50583927]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    apen_values = calculate_apen_for_large_data('preprocessed_eeg_data.csv', 'Fz', window_size=128, step_size=64)\n",
    "    print(\"Approximate Entropy values:\", apen_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "import os\n",
    "\n",
    "# Optimized Approximate Entropy function with Numba JIT\n",
    "@jit(nopython=True)\n",
    "def approximate_entropy(U, m, r):\n",
    "    \"\"\"\n",
    "    Compute Approximate Entropy (ApEn) of a time series.\n",
    "    \n",
    "    Parameters:\n",
    "    U : array-like\n",
    "        The input signal.\n",
    "    m : int\n",
    "        The length of compared run of data.\n",
    "    r : float\n",
    "        The filtering level (standard deviation * r).\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        Approximate entropy of the input signal.\n",
    "    \"\"\"\n",
    "    def _phi(m):\n",
    "        N = len(U)\n",
    "        count = 0\n",
    "        for i in range(N - m):\n",
    "            template = U[i:i + m]\n",
    "            matches = 0\n",
    "            for j in range(N - m):\n",
    "                candidate = U[j:j + m]\n",
    "                if np.max(np.abs(template - candidate)) <= r:\n",
    "                    matches += 1\n",
    "            count += np.log(matches / (N - m + 1))\n",
    "        return count / (N - m + 1)\n",
    "\n",
    "    return abs(_phi(m) - _phi(m + 1))\n",
    "\n",
    "# Function to calculate ApEn for each feature of a single patient\n",
    "def calculate_apen_for_patient(eeg_data, patient_id, m=2, r_factor=0.2):\n",
    "    \"\"\"\n",
    "    Calculate Approximate Entropy for all features of a single patient.\n",
    "    \n",
    "    Parameters:\n",
    "    eeg_data : DataFrame\n",
    "        EEG data of a single patient with 19 features (channels).\n",
    "    patient_id : str\n",
    "        Identifier for the patient (Patient_ID).\n",
    "    m : int\n",
    "        The embedding dimension for ApEn calculation.\n",
    "    r_factor : float\n",
    "        Tolerance factor for ApEn calculation.\n",
    "        \n",
    "    Returns:\n",
    "    DataFrame\n",
    "        A DataFrame with Patient_ID and ApEn values for each channel.\n",
    "    \"\"\"\n",
    "    apen_results = {'Patient_ID': patient_id}\n",
    "    \n",
    "    for channel in eeg_data.columns:\n",
    "        signal = eeg_data[channel].values\n",
    "        r = r_factor * np.std(signal)  # Set tolerance based on signal's standard deviation\n",
    "        apen_value = approximate_entropy(signal, m=m, r=r)\n",
    "        apen_results[channel] = apen_value\n",
    "    \n",
    "    # Convert the results to a DataFrame\n",
    "    apen_df = pd.DataFrame([apen_results])\n",
    "    \n",
    "    return apen_df\n",
    "\n",
    "# Function to calculate ApEn for each patient in a preprocessed file\n",
    "def process_patients_in_file(preprocessed_file,output_directory, m=2, r_factor=0.2):\n",
    "    \"\"\"\n",
    "    Calculate Approximate Entropy for all patients in the preprocessed file.\n",
    "    \n",
    "    Parameters:\n",
    "    preprocessed_file : str\n",
    "        Path to the preprocessed EEG CSV file containing multiple patients.\n",
    "    m : int\n",
    "        Embedding dimension for ApEn calculation.\n",
    "    r_factor : float\n",
    "        Tolerance factor for ApEn calculation.\n",
    "        \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Load preprocessed EEG data\n",
    "    df = pd.read_csv(preprocessed_file)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    # Group by Patient_ID and process each patient's data separately\n",
    "    patient_groups = df.groupby('Patient_ID')\n",
    "    \n",
    "    # Loop through each patient group and calculate ApEn for all 19 features\n",
    "    for patient_id, patient_data in patient_groups:\n",
    "        # Drop metadata columns (Label, Patient_ID) to focus only on EEG features\n",
    "        eeg_data = patient_data.drop(columns=['Label', 'Patient_ID'])\n",
    "        \n",
    "        # Calculate ApEn for the patient\n",
    "        apen_df = calculate_apen_for_patient(eeg_data, patient_id, m=m, r_factor=r_factor)\n",
    "        \n",
    "        # Save the result to a CSV file named after the patient\n",
    "        output_file = os.path.join(output_directory, f'approx_entropy_patient_{patient_id}.csv')\n",
    "        apen_df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved Approximate Entropy results for patient {patient_id} to {output_file}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Approximate Entropy results for patient v107_v107.csv to ApproximatedData\\approx_entropy_patient_v107_v107.csv.csv\n",
      "Saved Approximate Entropy results for patient v108_v108.csv to ApproximatedData\\approx_entropy_patient_v108_v108.csv.csv\n",
      "Saved Approximate Entropy results for patient v109_v109.csv to ApproximatedData\\approx_entropy_patient_v109_v109.csv.csv\n",
      "Saved Approximate Entropy results for patient v10p_v10p.csv to ApproximatedData\\approx_entropy_patient_v10p_v10p.csv.csv\n",
      "Saved Approximate Entropy results for patient v110_v110.csv to ApproximatedData\\approx_entropy_patient_v110_v110.csv.csv\n",
      "Saved Approximate Entropy results for patient v111_v111.csv to ApproximatedData\\approx_entropy_patient_v111_v111.csv.csv\n",
      "Saved Approximate Entropy results for patient v112_v112.csv to ApproximatedData\\approx_entropy_patient_v112_v112.csv.csv\n",
      "Saved Approximate Entropy results for patient v113_v113.csv to ApproximatedData\\approx_entropy_patient_v113_v113.csv.csv\n",
      "Saved Approximate Entropy results for patient v114_v114.csv to ApproximatedData\\approx_entropy_patient_v114_v114.csv.csv\n",
      "Saved Approximate Entropy results for patient v115_v115.csv to ApproximatedData\\approx_entropy_patient_v115_v115.csv.csv\n",
      "Saved Approximate Entropy results for patient v116_v116.csv to ApproximatedData\\approx_entropy_patient_v116_v116.csv.csv\n",
      "Saved Approximate Entropy results for patient v117_v117.csv to ApproximatedData\\approx_entropy_patient_v117_v117.csv.csv\n",
      "Saved Approximate Entropy results for patient v118_v118.csv to ApproximatedData\\approx_entropy_patient_v118_v118.csv.csv\n",
      "Saved Approximate Entropy results for patient v120_v120.csv to ApproximatedData\\approx_entropy_patient_v120_v120.csv.csv\n",
      "Saved Approximate Entropy results for patient v121_v121.csv to ApproximatedData\\approx_entropy_patient_v121_v121.csv.csv\n",
      "Saved Approximate Entropy results for patient v123_v123.csv to ApproximatedData\\approx_entropy_patient_v123_v123.csv.csv\n",
      "Saved Approximate Entropy results for patient v125_v125.csv to ApproximatedData\\approx_entropy_patient_v125_v125.csv.csv\n",
      "Saved Approximate Entropy results for patient v127_v127.csv to ApproximatedData\\approx_entropy_patient_v127_v127.csv.csv\n",
      "Saved Approximate Entropy results for patient v129_v129.csv to ApproximatedData\\approx_entropy_patient_v129_v129.csv.csv\n",
      "Saved Approximate Entropy results for patient v12p_v12p.csv to ApproximatedData\\approx_entropy_patient_v12p_v12p.csv.csv\n",
      "Saved Approximate Entropy results for patient v131_v131.csv to ApproximatedData\\approx_entropy_patient_v131_v131.csv.csv\n",
      "Saved Approximate Entropy results for patient v133_v133.csv to ApproximatedData\\approx_entropy_patient_v133_v133.csv.csv\n",
      "Saved Approximate Entropy results for patient v134_v134.csv to ApproximatedData\\approx_entropy_patient_v134_v134.csv.csv\n",
      "Saved Approximate Entropy results for patient v138_v138.csv to ApproximatedData\\approx_entropy_patient_v138_v138.csv.csv\n",
      "Saved Approximate Entropy results for patient v140_v140.csv to ApproximatedData\\approx_entropy_patient_v140_v140.csv.csv\n",
      "Saved Approximate Entropy results for patient v143_v143.csv to ApproximatedData\\approx_entropy_patient_v143_v143.csv.csv\n",
      "Saved Approximate Entropy results for patient v147_v147.csv to ApproximatedData\\approx_entropy_patient_v147_v147.csv.csv\n",
      "Saved Approximate Entropy results for patient v149_v149.csv to ApproximatedData\\approx_entropy_patient_v149_v149.csv.csv\n",
      "Saved Approximate Entropy results for patient v14p_v14p.csv to ApproximatedData\\approx_entropy_patient_v14p_v14p.csv.csv\n",
      "Saved Approximate Entropy results for patient v151_v151.csv to ApproximatedData\\approx_entropy_patient_v151_v151.csv.csv\n",
      "Saved Approximate Entropy results for patient v15p_v15p.csv to ApproximatedData\\approx_entropy_patient_v15p_v15p.csv.csv\n",
      "Saved Approximate Entropy results for patient v173_v173.csv to ApproximatedData\\approx_entropy_patient_v173_v173.csv.csv\n",
      "Saved Approximate Entropy results for patient v177_v177.csv to ApproximatedData\\approx_entropy_patient_v177_v177.csv.csv\n",
      "Saved Approximate Entropy results for patient v179_v179.csv to ApproximatedData\\approx_entropy_patient_v179_v179.csv.csv\n",
      "Saved Approximate Entropy results for patient v181_v181.csv to ApproximatedData\\approx_entropy_patient_v181_v181.csv.csv\n",
      "Saved Approximate Entropy results for patient v183_v183.csv to ApproximatedData\\approx_entropy_patient_v183_v183.csv.csv\n",
      "Saved Approximate Entropy results for patient v18p_v18p.csv to ApproximatedData\\approx_entropy_patient_v18p_v18p.csv.csv\n",
      "Saved Approximate Entropy results for patient v190_v190.csv to ApproximatedData\\approx_entropy_patient_v190_v190.csv.csv\n",
      "Saved Approximate Entropy results for patient v196_v196.csv to ApproximatedData\\approx_entropy_patient_v196_v196.csv.csv\n",
      "Saved Approximate Entropy results for patient v198_v198.csv to ApproximatedData\\approx_entropy_patient_v198_v198.csv.csv\n",
      "Saved Approximate Entropy results for patient v19p_v19p.csv to ApproximatedData\\approx_entropy_patient_v19p_v19p.csv.csv\n",
      "Saved Approximate Entropy results for patient v1p_v1p.csv to ApproximatedData\\approx_entropy_patient_v1p_v1p.csv.csv\n",
      "Saved Approximate Entropy results for patient v200_v200.csv to ApproximatedData\\approx_entropy_patient_v200_v200.csv.csv\n",
      "Saved Approximate Entropy results for patient v204_v204.csv to ApproximatedData\\approx_entropy_patient_v204_v204.csv.csv\n",
      "Saved Approximate Entropy results for patient v206_v206.csv to ApproximatedData\\approx_entropy_patient_v206_v206.csv.csv\n",
      "Saved Approximate Entropy results for patient v209_v209.csv to ApproximatedData\\approx_entropy_patient_v209_v209.csv.csv\n",
      "Saved Approximate Entropy results for patient v20p_v20p.csv to ApproximatedData\\approx_entropy_patient_v20p_v20p.csv.csv\n",
      "Saved Approximate Entropy results for patient v213_v213.csv to ApproximatedData\\approx_entropy_patient_v213_v213.csv.csv\n",
      "Saved Approximate Entropy results for patient v215_v215.csv to ApproximatedData\\approx_entropy_patient_v215_v215.csv.csv\n",
      "Saved Approximate Entropy results for patient v219_v219.csv to ApproximatedData\\approx_entropy_patient_v219_v219.csv.csv\n",
      "Saved Approximate Entropy results for patient v21p_v21p.csv to ApproximatedData\\approx_entropy_patient_v21p_v21p.csv.csv\n",
      "Saved Approximate Entropy results for patient v227_v227.csv to ApproximatedData\\approx_entropy_patient_v227_v227.csv.csv\n",
      "Saved Approximate Entropy results for patient v22p_v22p.csv to ApproximatedData\\approx_entropy_patient_v22p_v22p.csv.csv\n",
      "Saved Approximate Entropy results for patient v231_v231.csv to ApproximatedData\\approx_entropy_patient_v231_v231.csv.csv\n",
      "Saved Approximate Entropy results for patient v234_v234.csv to ApproximatedData\\approx_entropy_patient_v234_v234.csv.csv\n",
      "Saved Approximate Entropy results for patient v236_v236.csv to ApproximatedData\\approx_entropy_patient_v236_v236.csv.csv\n",
      "Saved Approximate Entropy results for patient v238_v238.csv to ApproximatedData\\approx_entropy_patient_v238_v238.csv.csv\n",
      "Saved Approximate Entropy results for patient v244_v244.csv to ApproximatedData\\approx_entropy_patient_v244_v244.csv.csv\n",
      "Saved Approximate Entropy results for patient v246_v246.csv to ApproximatedData\\approx_entropy_patient_v246_v246.csv.csv\n",
      "Saved Approximate Entropy results for patient v24p_v24p.csv to ApproximatedData\\approx_entropy_patient_v24p_v24p.csv.csv\n",
      "Saved Approximate Entropy results for patient v250_v250.csv to ApproximatedData\\approx_entropy_patient_v250_v250.csv.csv\n",
      "Saved Approximate Entropy results for patient v254_v254.csv to ApproximatedData\\approx_entropy_patient_v254_v254.csv.csv\n",
      "Saved Approximate Entropy results for patient v25p_v25p.csv to ApproximatedData\\approx_entropy_patient_v25p_v25p.csv.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Path to the preprocessed EEG file (containing multiple patients)\n",
    "    preprocessed_file = 'preprocessed_eeg_data.csv'\n",
    "    output_directory = 'ApproximatedData'\n",
    "    # Process all patients in the file\n",
    "    process_patients_in_file(preprocessed_file,output_directory, m=2, r_factor=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import jit\n",
    "\n",
    "# Optimized Approximate Entropy function with Numba JIT\n",
    "@jit(nopython=True)\n",
    "def approximate_entropy(U, m, r):\n",
    "    \"\"\"\n",
    "    Compute Approximate Entropy (ApEn) of a time series.\n",
    "    \n",
    "    Parameters:\n",
    "    U : array-like\n",
    "        The input signal.\n",
    "    m : int\n",
    "        The length of compared run of data.\n",
    "    r : float\n",
    "        The filtering level (standard deviation * r).\n",
    "    \n",
    "    Returns:\n",
    "    float\n",
    "        Approximate entropy of the input signal.\n",
    "    \"\"\"\n",
    "    def _phi(m):\n",
    "        N = len(U)\n",
    "        count = 0\n",
    "        for i in range(N - m):\n",
    "            template = U[i:i + m]\n",
    "            matches = 0\n",
    "            for j in range(N - m):\n",
    "                candidate = U[j:j + m]\n",
    "                if np.max(np.abs(template - candidate)) <= r:\n",
    "                    matches += 1\n",
    "            count += np.log(matches / (N - m + 1))\n",
    "        return count / (N - m + 1)\n",
    "\n",
    "    return abs(_phi(m) - _phi(m + 1))\n",
    "\n",
    "# Function to calculate ApEn for each feature of a single patient\n",
    "def calculate_apen_for_patient(eeg_data, patient_id, m=2, r_factor=0.2):\n",
    "    \"\"\"\n",
    "    Calculate Approximate Entropy for all features of a single patient.\n",
    "    \n",
    "    Parameters:\n",
    "    eeg_data : DataFrame\n",
    "        EEG data of a single patient with 19 features (channels).\n",
    "    patient_id : str\n",
    "        Identifier for the patient (Patient_ID).\n",
    "    m : int\n",
    "        The embedding dimension for ApEn calculation.\n",
    "    r_factor : float\n",
    "        Tolerance factor for ApEn calculation.\n",
    "        \n",
    "    Returns:\n",
    "    DataFrame\n",
    "        A DataFrame with Patient_ID and ApEn values for each channel.\n",
    "    \"\"\"\n",
    "    apen_results = {'Patient_ID': patient_id}\n",
    "    \n",
    "    for channel in eeg_data.columns:\n",
    "        signal = eeg_data[channel].values\n",
    "        r = r_factor * np.std(signal)  # Set tolerance based on signal's standard deviation\n",
    "        apen_value = approximate_entropy(signal, m=m, r=r)\n",
    "        apen_results[channel] = apen_value\n",
    "    \n",
    "    # Convert the results to a DataFrame\n",
    "    apen_df = pd.DataFrame([apen_results])\n",
    "    \n",
    "    return apen_df\n",
    "\n",
    "# Function to calculate ApEn for each patient and skip already processed patients\n",
    "def process_patients_in_file(preprocessed_file, output_directory, m=2, r_factor=0.2):\n",
    "    \"\"\"\n",
    "    Calculate Approximate Entropy for all patients in the preprocessed file,\n",
    "    skipping patients that have already been processed.\n",
    "    \n",
    "    Parameters:\n",
    "    preprocessed_file : str\n",
    "        Path to the preprocessed EEG CSV file containing multiple patients.\n",
    "    m : int\n",
    "        Embedding dimension for ApEn calculation.\n",
    "    r_factor : float\n",
    "        Tolerance factor for ApEn calculation.\n",
    "        \n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Load preprocessed EEG data\n",
    "    df = pd.read_csv(preprocessed_file)\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Group by Patient_ID and process each patient's data\n",
    "    patient_groups = df.groupby('Patient_ID')\n",
    "\n",
    "    # Get list of already processed patient files in the output directory\n",
    "    processed_patients = {\n",
    "        filename.replace('approx_entropy_patient_', '').replace('.csv', '')\n",
    "        for filename in os.listdir(output_directory)\n",
    "        if filename.startswith('approx_entropy_patient_')\n",
    "    }\n",
    "\n",
    "    # Process only patients that haven't been processed yet\n",
    "    for patient_id, patient_data in patient_groups:\n",
    "        # Convert patient_id to string and clean it\n",
    "        patient_id_str = str(patient_id).replace('.csv', '')\n",
    "\n",
    "        # Skip if this patient's file is already processed\n",
    "        if patient_id_str in processed_patients:\n",
    "            print(f\"Skipping patient {patient_id_str} (already processed)\")\n",
    "            continue\n",
    "\n",
    "        # Drop metadata columns (Label, Patient_ID) to focus only on EEG features\n",
    "        eeg_data = patient_data.drop(columns=['Label', 'Patient_ID'])\n",
    "        \n",
    "        # Calculate ApEn for the patient\n",
    "        apen_df = calculate_apen_for_patient(eeg_data, patient_id_str, m=m, r_factor=r_factor)\n",
    "        \n",
    "        # Save the result to a CSV file named after the patient\n",
    "        output_file = os.path.join(output_directory, f'approx_entropy_patient_{patient_id_str}.csv')\n",
    "        apen_df.to_csv(output_file, index=False)\n",
    "        print(f\"Saved Approximate Entropy results for patient {patient_id_str} to {output_file}\")\n",
    "\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed 'approx_entropy_patient_v108_v108.csv.csv' to 'approx_entropy_patient_v108_v108.csv'\n",
      "Renamed 'approx_entropy_patient_v109_v109.csv.csv' to 'approx_entropy_patient_v109_v109.csv'\n",
      "Renamed 'approx_entropy_patient_v10p_v10p.csv.csv' to 'approx_entropy_patient_v10p_v10p.csv'\n",
      "Renamed 'approx_entropy_patient_v110_v110.csv.csv' to 'approx_entropy_patient_v110_v110.csv'\n",
      "Renamed 'approx_entropy_patient_v111_v111.csv.csv' to 'approx_entropy_patient_v111_v111.csv'\n",
      "Renamed 'approx_entropy_patient_v112_v112.csv.csv' to 'approx_entropy_patient_v112_v112.csv'\n",
      "Renamed 'approx_entropy_patient_v113_v113.csv.csv' to 'approx_entropy_patient_v113_v113.csv'\n",
      "Renamed 'approx_entropy_patient_v114_v114.csv.csv' to 'approx_entropy_patient_v114_v114.csv'\n",
      "Renamed 'approx_entropy_patient_v115_v115.csv.csv' to 'approx_entropy_patient_v115_v115.csv'\n",
      "Renamed 'approx_entropy_patient_v116_v116.csv.csv' to 'approx_entropy_patient_v116_v116.csv'\n",
      "Renamed 'approx_entropy_patient_v117_v117.csv.csv' to 'approx_entropy_patient_v117_v117.csv'\n",
      "Renamed 'approx_entropy_patient_v118_v118.csv.csv' to 'approx_entropy_patient_v118_v118.csv'\n",
      "Renamed 'approx_entropy_patient_v120_v120.csv.csv' to 'approx_entropy_patient_v120_v120.csv'\n",
      "Renamed 'approx_entropy_patient_v121_v121.csv.csv' to 'approx_entropy_patient_v121_v121.csv'\n",
      "Renamed 'approx_entropy_patient_v123_v123.csv.csv' to 'approx_entropy_patient_v123_v123.csv'\n",
      "Renamed 'approx_entropy_patient_v125_v125.csv.csv' to 'approx_entropy_patient_v125_v125.csv'\n",
      "Renamed 'approx_entropy_patient_v127_v127.csv.csv' to 'approx_entropy_patient_v127_v127.csv'\n",
      "Renamed 'approx_entropy_patient_v129_v129.csv.csv' to 'approx_entropy_patient_v129_v129.csv'\n",
      "Renamed 'approx_entropy_patient_v12p_v12p.csv.csv' to 'approx_entropy_patient_v12p_v12p.csv'\n",
      "Renamed 'approx_entropy_patient_v131_v131.csv.csv' to 'approx_entropy_patient_v131_v131.csv'\n",
      "Renamed 'approx_entropy_patient_v133_v133.csv.csv' to 'approx_entropy_patient_v133_v133.csv'\n",
      "Renamed 'approx_entropy_patient_v134_v134.csv.csv' to 'approx_entropy_patient_v134_v134.csv'\n",
      "Renamed 'approx_entropy_patient_v138_v138.csv.csv' to 'approx_entropy_patient_v138_v138.csv'\n",
      "Renamed 'approx_entropy_patient_v140_v140.csv.csv' to 'approx_entropy_patient_v140_v140.csv'\n",
      "Renamed 'approx_entropy_patient_v143_v143.csv.csv' to 'approx_entropy_patient_v143_v143.csv'\n",
      "Renamed 'approx_entropy_patient_v147_v147.csv.csv' to 'approx_entropy_patient_v147_v147.csv'\n",
      "Renamed 'approx_entropy_patient_v149_v149.csv.csv' to 'approx_entropy_patient_v149_v149.csv'\n",
      "Renamed 'approx_entropy_patient_v14p_v14p.csv.csv' to 'approx_entropy_patient_v14p_v14p.csv'\n",
      "Renamed 'approx_entropy_patient_v151_v151.csv.csv' to 'approx_entropy_patient_v151_v151.csv'\n",
      "Renamed 'approx_entropy_patient_v15p_v15p.csv.csv' to 'approx_entropy_patient_v15p_v15p.csv'\n",
      "Renamed 'approx_entropy_patient_v173_v173.csv.csv' to 'approx_entropy_patient_v173_v173.csv'\n",
      "Renamed 'approx_entropy_patient_v177_v177.csv.csv' to 'approx_entropy_patient_v177_v177.csv'\n",
      "Renamed 'approx_entropy_patient_v179_v179.csv.csv' to 'approx_entropy_patient_v179_v179.csv'\n",
      "Renamed 'approx_entropy_patient_v181_v181.csv.csv' to 'approx_entropy_patient_v181_v181.csv'\n",
      "Renamed 'approx_entropy_patient_v183_v183.csv.csv' to 'approx_entropy_patient_v183_v183.csv'\n",
      "Renamed 'approx_entropy_patient_v18p_v18p.csv.csv' to 'approx_entropy_patient_v18p_v18p.csv'\n",
      "Renamed 'approx_entropy_patient_v190_v190.csv.csv' to 'approx_entropy_patient_v190_v190.csv'\n",
      "Renamed 'approx_entropy_patient_v196_v196.csv.csv' to 'approx_entropy_patient_v196_v196.csv'\n",
      "Renamed 'approx_entropy_patient_v198_v198.csv.csv' to 'approx_entropy_patient_v198_v198.csv'\n",
      "Renamed 'approx_entropy_patient_v19p_v19p.csv.csv' to 'approx_entropy_patient_v19p_v19p.csv'\n",
      "Renamed 'approx_entropy_patient_v1p_v1p.csv.csv' to 'approx_entropy_patient_v1p_v1p.csv'\n",
      "Renamed 'approx_entropy_patient_v200_v200.csv.csv' to 'approx_entropy_patient_v200_v200.csv'\n",
      "Renamed 'approx_entropy_patient_v204_v204.csv.csv' to 'approx_entropy_patient_v204_v204.csv'\n",
      "Renamed 'approx_entropy_patient_v206_v206.csv.csv' to 'approx_entropy_patient_v206_v206.csv'\n",
      "Renamed 'approx_entropy_patient_v209_v209.csv.csv' to 'approx_entropy_patient_v209_v209.csv'\n",
      "Renamed 'approx_entropy_patient_v20p_v20p.csv.csv' to 'approx_entropy_patient_v20p_v20p.csv'\n",
      "Renamed 'approx_entropy_patient_v213_v213.csv.csv' to 'approx_entropy_patient_v213_v213.csv'\n",
      "Renamed 'approx_entropy_patient_v215_v215.csv.csv' to 'approx_entropy_patient_v215_v215.csv'\n",
      "Renamed 'approx_entropy_patient_v219_v219.csv.csv' to 'approx_entropy_patient_v219_v219.csv'\n",
      "Renamed 'approx_entropy_patient_v21p_v21p.csv.csv' to 'approx_entropy_patient_v21p_v21p.csv'\n",
      "Renamed 'approx_entropy_patient_v227_v227.csv.csv' to 'approx_entropy_patient_v227_v227.csv'\n",
      "Renamed 'approx_entropy_patient_v22p_v22p.csv.csv' to 'approx_entropy_patient_v22p_v22p.csv'\n",
      "Renamed 'approx_entropy_patient_v231_v231.csv.csv' to 'approx_entropy_patient_v231_v231.csv'\n",
      "Renamed 'approx_entropy_patient_v234_v234.csv.csv' to 'approx_entropy_patient_v234_v234.csv'\n",
      "Renamed 'approx_entropy_patient_v236_v236.csv.csv' to 'approx_entropy_patient_v236_v236.csv'\n",
      "Renamed 'approx_entropy_patient_v238_v238.csv.csv' to 'approx_entropy_patient_v238_v238.csv'\n",
      "Renamed 'approx_entropy_patient_v244_v244.csv.csv' to 'approx_entropy_patient_v244_v244.csv'\n",
      "Renamed 'approx_entropy_patient_v246_v246.csv.csv' to 'approx_entropy_patient_v246_v246.csv'\n",
      "Renamed 'approx_entropy_patient_v24p_v24p.csv.csv' to 'approx_entropy_patient_v24p_v24p.csv'\n",
      "Renamed 'approx_entropy_patient_v250_v250.csv.csv' to 'approx_entropy_patient_v250_v250.csv'\n",
      "Renamed 'approx_entropy_patient_v254_v254.csv.csv' to 'approx_entropy_patient_v254_v254.csv'\n",
      "Renamed 'approx_entropy_patient_v25p_v25p.csv.csv' to 'approx_entropy_patient_v25p_v25p.csv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def rename_double_csv_files(folder_path):\n",
    "    # Loop through all files in the specified folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        # Check if the file ends with \".csv.csv\"\n",
    "        if file_name.endswith('.csv.csv'):\n",
    "            # Define the original file path\n",
    "            original_file_path = os.path.join(folder_path, file_name)\n",
    "            \n",
    "            # Create a new file name by replacing \".csv.csv\" with \".csv\"\n",
    "            new_file_name = file_name.replace('.csv.csv', '.csv')\n",
    "            new_file_path = os.path.join(folder_path, new_file_name)\n",
    "            \n",
    "            # Rename the file\n",
    "            os.rename(original_file_path, new_file_path)\n",
    "            print(f\"Renamed '{file_name}' to '{new_file_name}'\")\n",
    "\n",
    "# Specify the folder containing the files\n",
    "folder_path = \"ApproximatedData\"\n",
    "rename_double_csv_files(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "1    486963\n",
      "0    478980\n",
      "Name: count, dtype: int64\n",
      "Patient_ID\n",
      "v10p_v10p.csv    7983\n",
      "v107_v107.csv    7983\n",
      "v298_v298.csv    7983\n",
      "v297_v297.csv    7983\n",
      "v151_v151.csv    7983\n",
      "                 ... \n",
      "v263_v263.csv    7983\n",
      "v25p_v25p.csv    7983\n",
      "v254_v254.csv    7983\n",
      "v250_v250.csv    7983\n",
      "v60p_v60p.csv    7983\n",
      "Name: count, Length: 121, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"preprocessed_eeg_data.csv\")\n",
    "print(df['Label'].value_counts())\n",
    "print(df['Patient_ID'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Patient_ID  Label       Fp1       Fp2        F3        F4        C3  \\\n",
      "0    v1p_v1p.csv      1  1.642273  1.399319  1.788776  1.385568  1.894291   \n",
      "1    v3p_v3p.csv      1  1.395636  1.413645  1.650871  1.692185  1.595104   \n",
      "2    v6p_v6p.csv      1  1.704868  1.302344  1.764968  1.829080  1.755433   \n",
      "3    v8p_v8p.csv      1  1.743458  1.717706  1.756909  1.808859  1.870464   \n",
      "4  v10p_v10p.csv      1  1.898015  1.829305  1.914009  1.831493  1.963126   \n",
      "\n",
      "         C4        P3        P4  ...        O2        F7        F8        T3  \\\n",
      "0  1.719796  1.915635  1.512754  ...  1.733368  1.738399  1.422253  2.084362   \n",
      "1  1.714729  1.518903  1.553798  ...  1.854631  1.778350  1.499997  1.835588   \n",
      "2  1.876642  1.625831  1.811495  ...  1.806921  1.913643  1.914267  1.891086   \n",
      "3  1.882852  1.812890  1.892476  ...  1.873541  1.840289  1.428156  1.801163   \n",
      "4  1.932826  1.893168  1.834070  ...  1.565600  1.886567  1.570131  1.914168   \n",
      "\n",
      "         T4        T5        T6        Fz        Cz        Pz  \n",
      "0  1.351587  2.017587  1.636229  1.747181  1.593982  1.868023  \n",
      "1  1.666314  1.673319  1.744981  1.506660  1.732492  1.570463  \n",
      "2  1.878835  1.903650  1.940856  1.758291  1.969034  1.660543  \n",
      "3  1.709810  1.641722  1.866039  1.689779  1.932246  1.380826  \n",
      "4  1.839500  2.040556  1.903477  1.553348  1.935907  1.871050  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Label\n",
      "1    61\n",
      "0    60\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file\n",
    "data = pd.read_csv(\"Combined_Entropy.csv\")\n",
    "\n",
    "print(data.head())\n",
    "\n",
    "# Class distribution\n",
    "print(data['Label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
